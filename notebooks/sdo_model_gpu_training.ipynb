{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDO Solar Flare Prediction Model GPU Training\n",
    "\n",
    "This notebook imports the existing code from the SDO Models repository and runs the model training on GPU in Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Repository Cloning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/varshithgowdak/.pyenv/versions/3.9.6/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Install required packages from requirements.txt\n",
    "%pip install torch>=1.12.0 torchvision>=0.13.0 numpy>=1.22.0 pandas>=1.4.0 scikit-learn>=1.0.0 \\\n",
    "    matplotlib>=3.5.0 seaborn>=0.11.0 tqdm>=4.64.0 pillow>=9.0.0 h5py>=3.7.0 \\\n",
    "    opencv-python>=4.5.0 pytorch-lightning>=1.8.0 transformers>=4.21.0 captum>=0.5.0 shap>=0.41.0\n",
    "\n",
    "# Check if GPU is available\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "\n",
    "# Clone the repository (replace with your actual repository URL)\n",
    "!git clone https://github.com/your-username/SDOModels.git /content/SDOModels\n",
    "%cd /content/SDOModels\n",
    "\n",
    "# Setup for Google Drive for saving models\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!mkdir -p /content/drive/MyDrive/SDOBenchmark/models\n",
    "!mkdir -p /content/drive/MyDrive/SDOBenchmark/results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set Up Python Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the repository to Python path\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('/content/SDOModels')\n",
    "\n",
    "# Check the repository structure\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset paths\n",
    "DATA_URL = \"https://github.com/i4Ds/SDOBenchmark/archive/data-full.zip\"\n",
    "DOWNLOAD_PATH = \"/content/data-full.zip\"\n",
    "EXTRACT_PATH = \"/content\"\n",
    "DATASET_PATH = \"/content/SDOBenchmark_data\"\n",
    "\n",
    "# Create download and extraction functions\n",
    "import os\n",
    "import urllib.request\n",
    "from zipfile import ZipFile\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs(DATASET_PATH, exist_ok=True)\n",
    "\n",
    "# Function to download data with progress reporting\n",
    "def download_with_progress(url, output_path):\n",
    "    try:\n",
    "        logger.info(f\"Downloading data from {url}\")\n",
    "\n",
    "        def report_progress(block_num, block_size, total_size):\n",
    "            downloaded = block_num * block_size\n",
    "            percent = min(100, downloaded * 100 / total_size)\n",
    "            if total_size > 0:\n",
    "                sys.stdout.write(f\"\\rDownloaded {downloaded/1024/1024:.1f} MB of {total_size/1024/1024:.1f} MB ({percent:.1f}%)\")\n",
    "                sys.stdout.flush()\n",
    "\n",
    "        urllib.request.urlretrieve(url, output_path, reporthook=report_progress)\n",
    "        logger.info(\"\\nDownload completed successfully!\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error downloading data: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Function to extract dataset with validation\n",
    "def extract_with_validation(zip_path, extract_path):\n",
    "    try:\n",
    "        logger.info(f\"Extracting {zip_path} to {extract_path}\")\n",
    "        with ZipFile(zip_path, 'r') as zip_ref:\n",
    "            file_list = zip_ref.namelist()\n",
    "            logger.info(f\"Found {len(file_list)} files in the archive\")\n",
    "            zip_ref.extractall(extract_path)\n",
    "\n",
    "        extracted_dir = os.path.join(extract_path, \"SDOBenchmark-data-full\")\n",
    "        if os.path.exists(extracted_dir):\n",
    "            logger.info(\"Extraction completed successfully!\")\n",
    "            return True\n",
    "        else:\n",
    "            logger.error(f\"Extraction failed: {extracted_dir} not found\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error extracting data: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Function to organize extracted data\n",
    "def organize_data(source_dir, target_dir):\n",
    "    try:\n",
    "        logger.info(f\"Moving files from {source_dir} to {target_dir}\")\n",
    "        os.makedirs(target_dir, exist_ok=True)\n",
    "        os.system(f\"cp -r {source_dir}/* {target_dir}/\")\n",
    "\n",
    "        # Check for metadata files\n",
    "        training_meta = os.path.join(target_dir, \"training\", \"meta_data.csv\")\n",
    "        test_meta = os.path.join(target_dir, \"test\", \"meta_data.csv\")\n",
    "        \n",
    "        if os.path.exists(training_meta):\n",
    "            logger.info(f\"Found training metadata file at {training_meta}\")\n",
    "        else:\n",
    "            logger.warning(f\"Training metadata file not found at {training_meta}\")\n",
    "            \n",
    "        if os.path.exists(test_meta):\n",
    "            logger.info(f\"Found test metadata file at {test_meta}\")\n",
    "        else:\n",
    "            logger.warning(f\"Test metadata file not found at {test_meta}\")\n",
    "\n",
    "        for subdir in [\"training\", \"test\"]:\n",
    "            expected_dir = os.path.join(target_dir, subdir)\n",
    "            if os.path.exists(expected_dir):\n",
    "                logger.info(f\"Successfully copied {subdir} directory\")\n",
    "            else:\n",
    "                logger.error(f\"Failed to copy {subdir} directory\")\n",
    "                return False\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error organizing data: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Check if metadata files already exist\n",
    "training_meta = os.path.join(DATASET_PATH, \"training\", \"meta_data.csv\")\n",
    "test_meta = os.path.join(DATASET_PATH, \"test\", \"meta_data.csv\")\n",
    "metadata_exists = os.path.exists(training_meta) and os.path.exists(test_meta)\n",
    "\n",
    "# Download and prepare the dataset\n",
    "if not os.path.exists(os.path.join(DATASET_PATH, \"training\")) or \\\n",
    "   not os.path.exists(os.path.join(DATASET_PATH, \"test\")) or \\\n",
    "   not metadata_exists:\n",
    "\n",
    "    # 1. Download dataset\n",
    "    if not os.path.exists(DOWNLOAD_PATH):\n",
    "        success = download_with_progress(DATA_URL, DOWNLOAD_PATH)\n",
    "        if not success:\n",
    "            raise RuntimeError(\"Failed to download the dataset\")\n",
    "    else:\n",
    "        logger.info(f\"Using existing download at {DOWNLOAD_PATH}\")\n",
    "\n",
    "    # 2. Extract dataset\n",
    "    extracted_dir = os.path.join(EXTRACT_PATH, \"SDOBenchmark-data-full\")\n",
    "    if not os.path.exists(extracted_dir):\n",
    "        success = extract_with_validation(DOWNLOAD_PATH, EXTRACT_PATH)\n",
    "        if not success:\n",
    "            raise RuntimeError(\"Failed to extract the dataset\")\n",
    "    else:\n",
    "        logger.info(f\"Using existing extracted data at {extracted_dir}\")\n",
    "\n",
    "    # 3. Organize data\n",
    "    success = organize_data(extracted_dir, DATASET_PATH)\n",
    "    if not success:\n",
    "        raise RuntimeError(\"Failed to organize the dataset\")\n",
    "else:\n",
    "    logger.info(f\"Dataset already exists at {DATASET_PATH} with metadata files\")\n",
    "\n",
    "# Verify dataset structure and check for metadata files\n",
    "logger.info(\"Dataset structure verification:\")\n",
    "!ls -la {DATASET_PATH}\n",
    "\n",
    "# Check for metadata files in test and training folders\n",
    "if os.path.exists(training_meta):\n",
    "    logger.info(f\"Training metadata file found: {training_meta}\")\n",
    "    !head {training_meta}\n",
    "else:\n",
    "    logger.error(f\"Training metadata file not found at expected path: {training_meta}\")\n",
    "    raise FileNotFoundError(f\"Training metadata file not found: {training_meta}\")\n",
    "\n",
    "if os.path.exists(test_meta):\n",
    "    logger.info(f\"Test metadata file found: {test_meta}\")\n",
    "    !head {test_meta}\n",
    "else:\n",
    "    logger.error(f\"Test metadata file not found at expected path: {test_meta}\")\n",
    "    raise FileNotFoundError(f\"Test metadata file not found: {test_meta}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Import and Test Dataset Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset functionality from the repository\n",
    "from data.preprocessing import SDOBenchmarkDataset, get_data_loaders, SDODataAugmentation\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define paths to metadata files\n",
    "training_meta = os.path.join(DATASET_PATH, \"training\", \"meta_data.csv\")\n",
    "test_meta = os.path.join(DATASET_PATH, \"test\", \"meta_data.csv\")\n",
    "\n",
    "# Verify metadata files exist\n",
    "if not os.path.exists(training_meta):\n",
    "    raise FileNotFoundError(f\"Training metadata file not found: {training_meta}\")\n",
    "if not os.path.exists(test_meta):\n",
    "    raise FileNotFoundError(f\"Test metadata file not found: {test_meta}\")\n",
    "\n",
    "print(f\"Training metadata file exists: {os.path.exists(training_meta)}\")\n",
    "print(f\"Test metadata file exists: {os.path.exists(test_meta)}\")\n",
    "\n",
    "# Create data loaders using the existing metadata files\n",
    "data_loaders = get_data_loaders(\n",
    "    data_path=DATASET_PATH,\n",
    "    metadata_path={\n",
    "        'train': training_meta,\n",
    "        'test': test_meta\n",
    "    },\n",
    "    batch_size=8,\n",
    "    img_size=128,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "# Test the data loaders\n",
    "print(f\"Number of training batches: {len(data_loaders['train'])}\")\n",
    "print(f\"Number of validation batches: {len(data_loaders['val'])}\")\n",
    "print(f\"Number of test batches: {len(data_loaders['test'])}\")\n",
    "\n",
    "# Visualize a sample\n",
    "batch = next(iter(data_loaders['train']))\n",
    "print(\"Batch keys:\", batch.keys())\n",
    "print(f\"Magnetogram shape: {batch['magnetogram'].shape}\")\n",
    "print(f\"EUV shape: {batch['euv'].shape}\")\n",
    "\n",
    "# Plot an example\n",
    "sample_idx = 0\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].imshow(batch['magnetogram'][sample_idx, 0, 0].numpy(), cmap='gray')\n",
    "axes[0].set_title(\"Magnetogram (t=0)\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(batch['euv'][sample_idx, 0, 1].numpy(), cmap='hot') # Show 131Å channel\n",
    "axes[1].set_title(\"EUV 131Å (t=0)\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print sample metadata\n",
    "print(f\"Sample ID: {batch['sample_id'][sample_idx]}\")\n",
    "print(f\"Peak flux (log10): {batch['peak_flux'][sample_idx].item()}\")\n",
    "print(f\"GOES class: {batch['goes_class'][sample_idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Import Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model components\n",
    "from models.model import SolarFlareModel, SolarFlareLoss, PhysicsInformedRegularization\n",
    "\n",
    "# Create model instance with desired configuration\n",
    "model_config = {\n",
    "    'magnetogram_channels': 1,\n",
    "    'euv_channels': 8,\n",
    "    'pretrained': True,\n",
    "    'freeze_backbones': False,\n",
    "    'use_attention': True,\n",
    "    'fusion_method': 'concat',\n",
    "    'temporal_type': 'lstm',\n",
    "    'temporal_hidden_size': 512,\n",
    "    'temporal_num_layers': 2,\n",
    "    'dropout': 0.1,\n",
    "    'final_hidden_size': 512,\n",
    "    'use_uncertainty': True,\n",
    "    'use_multi_task': True\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "model = SolarFlareModel(**model_config)\n",
    "print(f\"Model initialized with {sum(p.numel() for p in model.parameters())} parameters\")\n",
    "\n",
    "# Create loss function\n",
    "loss_config = {\n",
    "    'regression_weight': 1.0,\n",
    "    'c_vs_0_weight': 0.5,\n",
    "    'm_vs_c_weight': 0.5,\n",
    "    'm_vs_0_weight': 0.5,\n",
    "    'use_uncertainty': True,\n",
    "    'uncertainty_weight': 0.1,\n",
    "    'use_multi_task': True\n",
    "}\n",
    "\n",
    "criterion = SolarFlareLoss(**loss_config)\n",
    "\n",
    "# Create physics-informed regularization\n",
    "physics_reg = PhysicsInformedRegularization(weight=0.1)\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "print(f\"Model moved to device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Set Up Training Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import training module\n",
    "from training.train import SolarFlareModule\n",
    "\n",
    "# Create configurations\n",
    "model_config = {\n",
    "    'magnetogram_channels': 1,\n",
    "    'euv_channels': 8,\n",
    "    'pretrained': True,\n",
    "    'freeze_backbones': False,\n",
    "    'use_attention': True,\n",
    "    'fusion_method': 'concat',\n",
    "    'temporal_type': 'lstm',\n",
    "    'temporal_hidden_size': 512,\n",
    "    'temporal_num_layers': 2,\n",
    "    'dropout': 0.1,\n",
    "    'final_hidden_size': 512,\n",
    "    'use_uncertainty': True,\n",
    "    'use_multi_task': True\n",
    "}\n",
    "\n",
    "loss_config = {\n",
    "    'regression_weight': 1.0,\n",
    "    'c_vs_0_weight': 0.5,\n",
    "    'm_vs_c_weight': 0.5,\n",
    "    'm_vs_0_weight': 0.5,\n",
    "    'use_uncertainty': True,\n",
    "    'uncertainty_weight': 0.1,\n",
    "    'use_multi_task': True,\n",
    "    'physics_reg_weight': 0.1,\n",
    "    'dynamic_weighting': True\n",
    "}\n",
    "\n",
    "optimizer_config = {\n",
    "    'lr': 5e-5,\n",
    "    'weight_decay': 0.001,\n",
    "    'scheduler': 'cosine',\n",
    "    'use_warmup': True,\n",
    "    'warmup_epochs': 5,\n",
    "    't_0': 20,\n",
    "    't_mult': 2,\n",
    "    'eta_min': 1e-7\n",
    "}\n",
    "\n",
    "# Define paths to metadata files\n",
    "training_meta = os.path.join(DATASET_PATH, \"training\", \"meta_data.csv\")\n",
    "test_meta = os.path.join(DATASET_PATH, \"test\", \"meta_data.csv\")\n",
    "\n",
    "# Update data_config to use the correct metadata paths\n",
    "data_config = {\n",
    "    'data_path': DATASET_PATH,\n",
    "    'metadata_path': {\n",
    "        'train': training_meta,\n",
    "        'test': test_meta\n",
    "    },\n",
    "    'batch_size': 8,\n",
    "    'img_size': 128,\n",
    "    'num_workers': 2,\n",
    "    'sample_type': 'all'\n",
    "}\n",
    "\n",
    "# Create the PyTorch Lightning module\n",
    "model = SolarFlareModule(\n",
    "    model_config=model_config,\n",
    "    loss_config=loss_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    data_config=data_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "# Create output directories with correct paths\n",
    "MODEL_OUTPUT_DIR = '/content/drive/MyDrive/SDOBenchmark/models'\n",
    "LOGS_OUTPUT_DIR = '/content/drive/MyDrive/SDOBenchmark/logs'\n",
    "RESULTS_OUTPUT_DIR = '/content/drive/MyDrive/SDOBenchmark/results'\n",
    "\n",
    "os.makedirs(MODEL_OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(LOGS_OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Configure callbacks\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=MODEL_OUTPUT_DIR,\n",
    "    filename='sdo_flare_model-{epoch:02d}-{val_loss:.2f}',\n",
    "    save_top_k=3,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_last=True\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "\n",
    "# Configure logger\n",
    "logger = TensorBoardLogger(\n",
    "    save_dir=LOGS_OUTPUT_DIR,\n",
    "    name='sdo_flare_model',\n",
    "    default_hp_metric=False\n",
    ")\n",
    "\n",
    "# Configure trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=50,\n",
    "    accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    devices=1,\n",
    "    callbacks=[checkpoint_callback, early_stopping, lr_monitor],\n",
    "    logger=logger,\n",
    "    log_every_n_steps=10,\n",
    "    gradient_clip_val=1.0,\n",
    "    precision=16 if torch.cuda.is_available() else 32  # Use mixed precision on GPU\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(\n",
    "    model,\n",
    "    train_dataloaders=data_loaders['train'],\n",
    "    val_dataloaders=data_loaders['val']\n",
    ")\n",
    "\n",
    "# Print best model path\n",
    "print(f\"Best model checkpoint: {checkpoint_callback.best_model_path}\")\n",
    "print(f\"Best validation loss: {checkpoint_callback.best_model_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model checkpoint\n",
    "best_model_path = checkpoint_callback.best_model_path\n",
    "model = SolarFlareModule.load_from_checkpoint(best_model_path)\n",
    "model.eval()\n",
    "\n",
    "# Run test evaluation\n",
    "test_results = trainer.test(model, dataloaders=data_loaders['test'])\n",
    "print(f\"Test results: {test_results}\")\n",
    "\n",
    "# Save evaluation results\n",
    "import json\n",
    "results_file = os.path.join(RESULTS_OUTPUT_DIR, 'test_results.json')\n",
    "with open(results_file, 'w') as f:\n",
    "    json.dump(test_results, f)\n",
    "print(f\"Saved test results to: {results_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualize Results and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions on test set\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, precision_recall_curve, auc\n",
    "\n",
    "# Get predictions on test set\n",
    "model.eval()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "all_sample_ids = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loaders['test']:\n",
    "        # Move inputs to device\n",
    "        magnetogram = batch['magnetogram'].to(device)\n",
    "        euv = batch['euv'].to(device)\n",
    "        \n",
    "        # Get predictions\n",
    "        outputs = model(magnetogram, euv)\n",
    "        \n",
    "        # Extract values\n",
    "        pred_flux = outputs['regression'][0].cpu().numpy() if isinstance(outputs['regression'], tuple) else outputs['regression'].cpu().numpy()\n",
    "        target_flux = batch['peak_flux'].numpy()\n",
    "        \n",
    "        # Store predictions and targets\n",
    "        for i in range(len(pred_flux)):\n",
    "            all_preds.append({\n",
    "                'flux': pred_flux[i][0],\n",
    "                'c_vs_0': outputs['c_vs_0'][i].item(),\n",
    "                'm_vs_c': outputs['m_vs_c'][i].item(),\n",
    "                'm_vs_0': outputs['m_vs_0'][i].item()\n",
    "            })\n",
    "            all_targets.append({\n",
    "                'flux': target_flux[i].item(),\n",
    "                'c_vs_0': batch['is_c_or_above'][i].item(),\n",
    "                'm_vs_c': batch['is_m_or_above'][i].item(),\n",
    "                'm_vs_0': batch['is_m_vs_quiet'][i].item()\n",
    "            })\n",
    "            all_sample_ids.append(batch['sample_id'][i])\n",
    "\n",
    "# Convert to numpy arrays for easier plotting\n",
    "pred_flux = np.array([p['flux'] for p in all_preds])\n",
    "target_flux = np.array([t['flux'] for t in all_targets])\n",
    "\n",
    "pred_c_vs_0 = np.array([p['c_vs_0'] for p in all_preds])\n",
    "target_c_vs_0 = np.array([t['c_vs_0'] for t in all_targets])\n",
    "\n",
    "# Plot regression results\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(target_flux, pred_flux, alpha=0.5)\n",
    "plt.plot([-8, -3], [-8, -3], 'r--')  # Diagonal line\n",
    "plt.xlabel('True log10(Peak Flux)')\n",
    "plt.ylabel('Predicted log10(Peak Flux)')\n",
    "plt.title('Regression Performance')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save results to the correct paths\n",
    "PLOTS_DIR = os.path.join(RESULTS_OUTPUT_DIR, 'plots')\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "regression_plot_file = os.path.join(PLOTS_DIR, 'regression_performance.png')\n",
    "plt.savefig(regression_plot_file)\n",
    "plt.show()\n",
    "print(f\"Saved regression plot to: {regression_plot_file}\")\n",
    "\n",
    "# Plot classification results\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# ROC curve\n",
    "plt.subplot(1, 2, 1)\n",
    "fpr, tpr, _ = roc_curve(target_c_vs_0, pred_c_vs_0)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve (C-class or above)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Confusion matrix\n",
    "plt.subplot(1, 2, 2)\n",
    "pred_c_vs_0_binary = (pred_c_vs_0 > 0.5).astype(int)\n",
    "cm = confusion_matrix(target_c_vs_0, pred_c_vs_0_binary)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix (C-class or above)')\n",
    "\n",
    "plt.tight_layout()\n",
    "classification_plot_file = os.path.join(PLOTS_DIR, 'classification_performance.png')\n",
    "plt.savefig(classification_plot_file)\n",
    "plt.show()\n",
    "print(f\"Saved classification plot to: {classification_plot_file}\")\n",
    "\n",
    "# Save predictions for further analysis\n",
    "predictions_df = pd.DataFrame({\n",
    "    'sample_id': all_sample_ids,\n",
    "    'true_flux': [t['flux'] for t in all_targets],\n",
    "    'pred_flux': [p['flux'] for p in all_preds],\n",
    "    'true_c_vs_0': [t['c_vs_0'] for t in all_targets],\n",
    "    'pred_c_vs_0': [p['c_vs_0'] for p in all_preds],\n",
    "    'true_m_vs_c': [t['m_vs_c'] for t in all_targets],\n",
    "    'pred_m_vs_c': [p['m_vs_c'] for p in all_preds],\n",
    "    'true_m_vs_0': [t['m_vs_0'] for t in all_targets],\n",
    "    'pred_m_vs_0': [p['m_vs_0'] for p in all_preds]\n",
    "})\n",
    "\n",
    "PREDICTIONS_PATH = os.path.join(RESULTS_OUTPUT_DIR, 'predictions.csv')\n",
    "predictions_df.to_csv(PREDICTIONS_PATH, index=False)\n",
    "print(f\"Saved predictions to: {PREDICTIONS_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
